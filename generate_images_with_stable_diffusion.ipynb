{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gilliangold/graphics-cpsc479/blob/main/Copy_of_generate_images_with_stable_diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxmml-By8QLG"
      },
      "source": [
        "# High-performance image generation using Stable Diffusion in KerasCV\n",
        "\n",
        "**Authors:** [fchollet](https://twitter.com/fchollet), [lukewood](https://twitter.com/luke_wood_ml), [divamgupta](https://github.com/divamgupta)<br>\n",
        "**Date created:** 2022/09/25<br>\n",
        "**Last modified:** 2022/12/17 by Gillian Gold<br>\n",
        "**Description:** Generate new images using KerasCV's StableDiffusion model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W46K7M1k8QLS"
      },
      "source": [
        "## Wait, how does this even work?\n",
        "\n",
        "![The Stable Diffusion architecture](https://i.imgur.com/2uC8rYJ.png)\n",
        "\n",
        "All-in-all, it's a pretty simple system -- the Keras implementation\n",
        "fits in four files that represent less than 500 lines of code in total:\n",
        "\n",
        "- [text_encoder.py](https://github.com/keras-team/keras-cv/blob/master/keras_cv/models/generative/stable_diffusion/text_encoder.py): 87 LOC\n",
        "- [diffusion_model.py](https://github.com/keras-team/keras-cv/blob/master/keras_cv/models/generative/stable_diffusion/diffusion_model.py): 181 LOC\n",
        "- [decoder.py](https://github.com/keras-team/keras-cv/blob/master/keras_cv/models/generative/stable_diffusion/decoder.py): 86 LOC\n",
        "- [stable_diffusion.py](https://github.com/keras-team/keras-cv/blob/master/keras_cv/models/generative/stable_diffusion/stable_diffusion.py): 106 LOC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTyQMcZn8QLL"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Generate novel images based on a text prompt using\n",
        "the KerasCV implementation of [stability.ai](https://stability.ai/)'s text-to-image model,\n",
        "[Stable Diffusion](https://github.com/CompVis/stable-diffusion).\n",
        "\n",
        "To get started, let's install a few dependencies and sort out some imports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSjB9TLi8QLM",
        "outputId": "52b697d3-fecd-48de-e6b8-9628ecb99b21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 588.3 MB 19 kB/s \n",
            "\u001b[K     |████████████████████████████████| 394 kB 56.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 439 kB 53.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 69.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 49.8 MB/s \n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following packages will be REMOVED:\n",
            "  libcudnn8-dev\n",
            "The following held packages will be changed:\n",
            "  libcudnn8\n",
            "The following packages will be DOWNGRADED:\n",
            "  libcudnn8\n",
            "0 upgraded, 0 newly installed, 1 downgraded, 1 to remove and 18 not upgraded.\n",
            "Need to get 430 MB of archives.\n",
            "After this operation, 1,392 MB disk space will be freed.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n",
            "Fetched 430 MB in 8s (53.5 MB/s)\n",
            "(Reading database ... 124016 files and directories currently installed.)\n",
            "Removing libcudnn8-dev (8.1.1.33-1+cuda11.2) ...\n",
            "update-alternatives: removing manually selected alternative - switching libcudnn to auto mode\n",
            "\u001b[1mdpkg:\u001b[0m \u001b[1;33mwarning:\u001b[0m downgrading libcudnn8 from 8.1.1.33-1+cuda11.2 to 8.1.0.77-1+cuda11.2\n",
            "(Reading database ... 123993 files and directories currently installed.)\n",
            "Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n",
            "Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.1.1.33-1+cuda11.2) ...\n",
            "Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow keras_cv --upgrade --quiet\n",
        "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qZ8codkp8QLN"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import keras_cv\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MauryUSB8QLO"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "First, we construct a model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUWfMlme8QLO",
        "outputId": "e96da41a-1422-482f-8077-701a34bf99ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/openai/CLIP/blob/main/clip/bpe_simple_vocab_16e6.txt.gz?raw=true\n",
            "1356917/1356917 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "By using this model checkpoint, you acknowledge that its usage is subject to the terms of the CreativeML Open RAIL-M license at https://raw.githubusercontent.com/CompVis/stable-diffusion/main/LICENSE\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_encoder.h5\n",
            "492466864/492466864 [==============================] - 3s 0us/step\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_diffusion_model.h5\n",
            "3439090152/3439090152 [==============================] - 66s 0us/step\n",
            "Downloading data from https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_decoder.h5\n",
            "198180272/198180272 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "model = keras_cv.models.StableDiffusion(img_width=512, img_height=512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEQXQ8CT8QLP"
      },
      "source": [
        "Next, we give it a prompt:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "apU1DcLd8QLP"
      },
      "outputs": [],
      "source": [
        "def plot_images(images):\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    for i in range(len(images)):\n",
        "        ax = plt.subplot(1, len(images), i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7yDlf9eAQei"
      },
      "source": [
        "# Exploring Specificity of Images Related to Dogs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mq6f6XfNXt6U",
        "outputId": "c0d3c969-e4ee-40a1-cd22-60cf8e1a5e88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 3/25 [==>...........................] - ETA: 1:00:13"
          ]
        }
      ],
      "source": [
        "dog = model.text_to_image(\"dog\", batch_size=4)\n",
        "plot_images(dog)\n",
        "\n",
        "dog_beach_general = model.text_to_image(\"dog on the beach\", batch_size=4)\n",
        "plot_images(dog_beach_general)\n",
        "\n",
        "golden_retriever_beach = model.text_to_image(\"golden retriever on the beach\", batch_size=4)\n",
        "plot_images(golden_retriever_beach)\n",
        "\n",
        "golden_retriever_sitting_beach = model.text_to_image(\"golden retriever sitting on the beach\", batch_size=4)\n",
        "plot_images(golden_retriever_sitting_beach)\n",
        "\n",
        "golden_retriever_puppy_sitting_beach = model.text_to_image(\"golden retriever puppy sitting on the beach\", batch_size=4)\n",
        "plot_images(golden_retriever_puppy_sitting_beach)\n",
        "\n",
        "puppy_sand_sitting_beach = model.text_to_image(\"golden retriever puppy sitting on the sand of the beach\", batch_size=4)\n",
        "plot_images(puppy_sand_sitting_beach)\n",
        "\n",
        "happy_puppy_sand_sitting_beach = model.text_to_image(\"happy golden retriever puppy sitting on the sand of the beach\", batch_size=4)\n",
        "plot_images(happy_puppy_sand_sitting_beach)\n",
        "\n",
        "sad_puppy_sand_sitting_beach = model.text_to_image(\"sad golden retriever puppy sitting on the sand of the beach\", batch_size=4)\n",
        "plot_images(sad_puppy_sand_sitting_beach)\n",
        "\n",
        "comics_puppy_sand_sitting_beach = model.text_to_image(\"golden retriever sitting on the beach in comics\", batch_size=4)\n",
        "plot_images(comics_puppy_sand_sitting_beach)\n",
        "\n",
        "van_gogh_puppy_sand_sitting_beach = model.text_to_image(\"golden retriever sitting on the beach in comics\", batch_size=4)\n",
        "plot_images(van_gogh_puppy_sand_sitting_beach)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sObXop1VAbC0"
      },
      "source": [
        "# Exploring Specificity of Images Related to Flowers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "twIeQv_c5Ns7"
      },
      "outputs": [],
      "source": [
        "flower = model.text_to_image(\"flower\", batch_size=4)\n",
        "plot_images(flower)\n",
        "\n",
        "flower_forest_general = model.text_to_image(\"flower in the forest\", batch_size=4)\n",
        "plot_images(dog_beach_general)\n",
        "\n",
        "iris_forest = model.text_to_image(\"iris in the forest\", batch_size=4)\n",
        "plot_images(iris_forest)\n",
        "\n",
        "iris_growing_forest = model.text_to_image(\"iris growing in the forest\", batch_size=4)\n",
        "plot_images(golden_retriever_sitting_beach)\n",
        "\n",
        "purple_iris_forest = model.text_to_image(\"purple iris growing in the forest\", batch_size=4)\n",
        "plot_images(purple_iris_forest)\n",
        "\n",
        "purple_iris_forest_pine = model.text_to_image(\"purple iris growing in the forest of pine trees\", batch_size=4)\n",
        "plot_images(purple_iris_forest_pine)\n",
        "\n",
        "healthy_purple_iris_forest_pine = model.text_to_image(\"healthy purple iris growing in the forest of pine trees\", batch_size=4)\n",
        "plot_images(healthy_purple_iris_forest_pine)\n",
        "\n",
        "dying_purple_iris_forest_pine = model.text_to_image(\"dying purple iris growing in the forest of pine trees\", batch_size=4)\n",
        "plot_images(dying_purple_iris_forest_pine)\n",
        "\n",
        "comics_purple_iris_forest = model.text_to_image(\"purple iris growing in the forest in comics\", batch_size=4)\n",
        "plot_images(comics_purple_iris_forest)\n",
        "\n",
        "van_gogh_purple_iris_forest = model.text_to_image(\"purple iris growing in the forest in comics\", batch_size=4)\n",
        "plot_images(van_gogh_purple_iris_forest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFVWI8FXAnKz"
      },
      "source": [
        "# User Study"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt1)\n",
        "\n",
        "prompt2 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt2)\n",
        "\n",
        "prompt3 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt3)"
      ],
      "metadata": {
        "id": "j_i5Ovzcy9gR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt1)\n",
        "\n",
        "prompt2 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt2)\n",
        "\n",
        "prompt3 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt3)"
      ],
      "metadata": {
        "id": "HYDlhoHgy-xE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt1)\n",
        "\n",
        "prompt2 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt2)\n",
        "\n",
        "prompt3 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt3)"
      ],
      "metadata": {
        "id": "Eo-dr0gLy_Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt1)\n",
        "\n",
        "prompt2 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt2)\n",
        "\n",
        "prompt3 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt3)"
      ],
      "metadata": {
        "id": "tCjDO_b2y_hQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt1)\n",
        "\n",
        "prompt2 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt2)\n",
        "\n",
        "prompt3 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt3)"
      ],
      "metadata": {
        "id": "y6xMTXkky_1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt1)\n",
        "\n",
        "prompt2 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt2)\n",
        "\n",
        "prompt3 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt3)"
      ],
      "metadata": {
        "id": "UQFG_6PfzAKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt1)\n",
        "\n",
        "prompt2 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt2)\n",
        "\n",
        "prompt3 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt3)"
      ],
      "metadata": {
        "id": "r39HKFsWzAcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt1)\n",
        "\n",
        "prompt2 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt2)\n",
        "\n",
        "prompt3 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt3)"
      ],
      "metadata": {
        "id": "v9Sc0N-4zAw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt1)\n",
        "\n",
        "prompt2 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt2)\n",
        "\n",
        "prompt3 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt3)"
      ],
      "metadata": {
        "id": "GNtWtqQIzBE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt1 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt1)\n",
        "\n",
        "prompt2 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt2)\n",
        "\n",
        "prompt3 = model.text_to_image(\" \", batch_size=4)\n",
        "plot_images(prompt3)"
      ],
      "metadata": {
        "id": "oqTugqRlzBZK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
